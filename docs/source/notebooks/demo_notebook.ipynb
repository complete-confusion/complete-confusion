{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46bfbae5",
   "metadata": {},
   "source": [
    "# Complete Confusion Demo\n",
    "\n",
    "This notebook demonstrates the basic functionality of the Complete Confusion library for generating performance metrics and visualizations for classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35cd1c",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46804651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import complete_confusion as cc\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8bb11",
   "metadata": {},
   "source": [
    "## Basic Example\n",
    "\n",
    "Let's start with a simple example using predefined data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46cd40cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "save_performance_metrics_to_html() got an unexpected keyword argument 'output_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m class_names = [\u001b[33m\"\u001b[39m\u001b[33mClass A\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mClass B\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mClass C\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Generate performance metrics HTML report\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mcc\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_performance_metrics_to_html\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbasic_example_metrics.html\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBasic example report generated: basic_example_metrics.html\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: save_performance_metrics_to_html() got an unexpected keyword argument 'output_file'"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "predictions = [0, 1, 0, 2, 1, 2, 0, 1, 2, 0]\n",
    "true_labels = [0, 1, 0, 2, 0, 2, 2, 1, 1, 0]\n",
    "class_names = [\"Class A\", \"Class B\", \"Class C\"]\n",
    "\n",
    "# Generate performance metrics HTML report\n",
    "cc.save_performance_metrics_to_html(\n",
    "    predictions, \n",
    "    true_labels, \n",
    "    class_names,\n",
    "    output_file=\"basic_example_metrics.html\"\n",
    ")\n",
    "\n",
    "print(\"Basic example report generated: basic_example_metrics.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c27eb",
   "metadata": {},
   "source": [
    "## Realistic Example with Synthetic Data\n",
    "\n",
    "Now let's create a more realistic example using scikit-learn to generate synthetic data and train a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=3,\n",
    "    n_classes=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d7868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(f\"Model trained successfully!\")\n",
    "print(f\"Predictions shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names\n",
    "class_names = [f\"Category_{i}\" for i in range(4)]\n",
    "\n",
    "# Generate comprehensive performance report\n",
    "cc.save_performance_metrics_to_html(\n",
    "    predictions,\n",
    "    y_test,\n",
    "    class_names,\n",
    "    output_file=\"random_forest_performance.html\"\n",
    ")\n",
    "\n",
    "print(\"Random Forest performance report generated: random_forest_performance.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907bf365",
   "metadata": {},
   "source": [
    "## Binary Classification Example\n",
    "\n",
    "Let's also demonstrate binary classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate binary classification data\n",
    "X_binary, y_binary = make_classification(\n",
    "    n_samples=500,\n",
    "    n_features=10,\n",
    "    n_informative=8,\n",
    "    n_redundant=1,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
    "    X_binary, y_binary, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "binary_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "binary_model.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "# Make predictions\n",
    "binary_predictions = binary_model.predict(X_test_bin)\n",
    "\n",
    "# Generate report\n",
    "binary_class_names = [\"Negative\", \"Positive\"]\n",
    "cc.save_performance_metrics_to_html(\n",
    "    binary_predictions,\n",
    "    y_test_bin,\n",
    "    binary_class_names,\n",
    "    output_file=\"binary_classification_performance.html\"\n",
    ")\n",
    "\n",
    "print(\"Binary classification report generated: binary_classification_performance.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c12a4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Basic usage** with predefined data\n",
    "2. **Multi-class classification** with synthetic data and Random Forest\n",
    "3. **Binary classification** example\n",
    "\n",
    "Each example generates an HTML report containing:\n",
    "- Interactive confusion matrix\n",
    "- Performance metrics (precision, recall, F1-score)\n",
    "- Per-class statistics\n",
    "- Detailed visualizations\n",
    "\n",
    "The generated HTML files can be opened in any web browser for interactive exploration of the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "complete-confusion-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
